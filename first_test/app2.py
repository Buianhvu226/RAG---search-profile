import pandas as pd
import chromadb
from sentence_transformers import SentenceTransformer
import streamlit as st
import google.generativeai as genai
import re
import os
import time # Äá»ƒ Ä‘o thá»i gian
import concurrent.futures # Cho Ä‘a luá»“ng
from threading import Lock # Äá»ƒ báº£o vá»‡ truy cáº­p vÃ o tÃ i nguyÃªn dÃ¹ng chung (náº¿u cáº§n)

st.set_page_config(layout="wide")
# --- Cáº¥u hÃ¬nh vÃ  Khá»Ÿi táº¡o ---

# !!! QUAN TRá»ŒNG: Thay tháº¿ báº±ng API Key thá»±c cá»§a báº¡n !!!
GOOGLE_API_KEY = "AIzaSyBCAqTBZSg7wXK_Jg-JnXW0rZkRJ-VRU64" # <--- THAY Báº°NG API KEY Cá»¦A Báº N
# Chá»n model Gemini phÃ¹ há»£p (Flash thÆ°á»ng nhanh vÃ  ráº» hÆ¡n)
GEMINI_MODEL_NAME = 'gemini-2.0-flash' # Hoáº·c 'gemini-2.0-advanced-latest'

try:
    genai.configure(api_key=GOOGLE_API_KEY)
    # Kiá»ƒm tra sá»± tá»“n táº¡i cá»§a model (tÃ¹y chá»n)
    # genai.get_generative_model(GEMINI_MODEL_NAME)
except Exception as e:
    st.error(f"Lá»—i cáº¥u hÃ¬nh Google API Key hoáº·c model '{GEMINI_MODEL_NAME}': {e}. HÃ£y Ä‘áº£m báº£o báº¡n Ä‘Ã£ cung cáº¥p API Key há»£p lá»‡ vÃ  model tá»“n táº¡i.")
    st.stop()

DATA_FILE = "profiles_detailed_data_cleaned.csv"
PERSIST_DIRECTORY = "chroma_db_v3_gemini" # ThÆ° má»¥c DB má»›i cho phiÃªn báº£n nÃ y
MAX_WORKERS_GEMINI = 8 # Sá»‘ luá»“ng tá»‘i Ä‘a Ä‘á»ƒ gá»i Gemini API Ä‘á»“ng thá»i (Ä‘iá»u chá»‰nh náº¿u gáº·p lá»—i rate limit)

# HÃ m táº£i dá»¯ liá»‡u
@st.cache_data
def load_data(file_path):
    try:
        return pd.read_csv(file_path)
    except FileNotFoundError:
        st.error(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y file dá»¯ liá»‡u táº¡i '{file_path}'.")
        st.stop()

df = load_data(DATA_FILE)

# --- CÃ¡c HÃ m Tiá»n xá»­ lÃ½ (Giá»¯ nguyÃªn tá»« phiÃªn báº£n trÆ°á»›c) ---

def normalize_name(name):
    if pd.isna(name) or name == 'nan': return ""
    name = str(name).lower().strip()
    name = re.sub(r'[^\wÃ€-á»¹\s-]', '', name)
    name = re.sub(r'\s+', ' ', name).strip()
    return name

def extract_years(text):
    if pd.isna(text) or text == 'nan': return []
    text = str(text).lower()
    years = []
    full_years = re.findall(r'\b(19\d{2}|20\d{2})\b', text)
    years.extend(full_years)
    short_years = re.findall(r'nÄƒm\s+(\d{2})\b', text)
    current_year = pd.Timestamp.now().year
    for year in short_years:
        year_int = int(year)
        if year_int < ((current_year % 100) + 10): full_year = "20" + year
        else: full_year = "19" + year
        if int(full_year) <= current_year: years.append(full_year)
    return sorted(list(set(years)))

def enhance_text(row):
    name = normalize_name(row["Há» vÃ  tÃªn"])
    birth_year = str(row["NÄƒm sinh"])
    father = normalize_name(row["TÃªn cha"])
    mother = normalize_name(row["TÃªn máº¹"])
    siblings = normalize_name(row["TÃªn anh-chá»‹-em"])
    details = str(row["Chi tiáº¿t"])
    lost_year = str(row["NÄƒm tháº¥t láº¡c"])

    detail_years = extract_years(details)
    all_years = extract_years(birth_year) + extract_years(lost_year) + detail_years
    years_text = " ".join(sorted(list(set(all_years))))

    locations = re.findall(r'(?:á»Ÿ|táº¡i|quÃª\s+á»Ÿ|tá»‰nh|tp\.|thÃ nh\s+phá»‘|quáº­n|huyá»‡n|xÃ£)\s+([A-ZÃ€-á»¸][a-zÃ -á»¹]+(?:\s+[A-ZÃ€-á»¸][a-zÃ -á»¹]+)*)', details)
    location_text = " ".join(sorted(list(set(l.strip() for l in locations)))).lower()

    real_name_match = re.search(r'(?:tÃªn\s+tháº­t|tÃªn\s+gá»i)\s+(?:lÃ )?\s+([A-ZÃ€-á»¸][a-zÃ -á»¹]*(?:\s+[A-ZÃ€-á»¸][a-zÃ -á»¹]*){0,2})', details, re.IGNORECASE)
    real_name = normalize_name(real_name_match.group(1)) if real_name_match else ""

    circumstance_keywords = ["nháº­n nuÃ´i", "cho ngÆ°á»i", "cho Ä‘i", "bá»‹ bá»", "tháº¥t láº¡c", "li dá»‹", "ly dá»‹", "ly hÃ´n", "giáº­n nhau", "má»“ cÃ´i", "Ä‘i láº¡c", "bÃ¡n con"]
    circumstance_text = " ".join([kw for kw in circumstance_keywords if kw in details.lower()])

    enhanced = f"TÃªn: {name}. TÃªn tháº­t/gá»i: {real_name}. Cha: {father}. Máº¹: {mother}. "
    enhanced += f"NÄƒm sinh/tháº¥t láº¡c/sá»± kiá»‡n: {years_text}. "
    enhanced += f"Anh chá»‹ em: {siblings}. "
    enhanced += f"Äá»‹a Ä‘iá»ƒm: {location_text}. HoÃ n cáº£nh: {circumstance_text}. "
    enhanced += f"Chi tiáº¿t khÃ¡c: {details.lower()}"
    return enhanced

# Ãp dá»¥ng hÃ m enhance_text (chá»‰ cháº¡y náº¿u cá»™t chÆ°a cÃ³)
if "enhanced_text" not in df.columns or df["enhanced_text"].isnull().any():
     print("Äang táº¡o/cáº­p nháº­t cá»™t enhanced_text...")
     df["enhanced_text"] = df.apply(enhance_text, axis=1)
     print("Táº¡o/cáº­p nháº­t cá»™t enhanced_text hoÃ n táº¥t.")
     # LÆ°u láº¡i df Ä‘Ã£ xá»­ lÃ½ Ä‘á»ƒ láº§n sau cháº¡y nhanh hÆ¡n (tÃ¹y chá»n)
     # df.to_csv("profiles_processed_v3.csv", index=False)


# --- MÃ´ hÃ¬nh Embedding vÃ  VectorDB (Giá»¯ nguyÃªn) ---

@st.cache_resource
def load_embedding_model():
    model_name = 'paraphrase-multilingual-MiniLM-L12-v2'
    try:
        return SentenceTransformer(model_name)
    except Exception as e:
        st.error(f"Lá»—i táº£i mÃ´ hÃ¬nh Sentence Transformer '{model_name}': {e}")
        st.stop()

embedding_model = load_embedding_model()

@st.cache_resource
def init_chroma_db():
    print(f"Khá»Ÿi táº¡o hoáº·c táº£i ChromaDB tá»«: {PERSIST_DIRECTORY}")
    os.makedirs(PERSIST_DIRECTORY, exist_ok=True)
    try:
        client = chromadb.PersistentClient(path=PERSIST_DIRECTORY)
        collection_name = "profiles_semantic_v1" # Äá»•i tÃªn collection
        collection = client.get_or_create_collection(collection_name)

        if collection.count() < len(df):
            st.warning(f"Collection '{collection_name}' Ä‘ang trá»‘ng hoáº·c chÆ°a Ä‘á»§ dá»¯ liá»‡u. Tiáº¿n hÃ nh náº¡p...")
            if collection.count() > 0:
                print(f"XÃ³a dá»¯ liá»‡u cÅ© trong collection '{collection_name}'...")
                existing_ids = collection.get(include=[])['ids']
                if existing_ids: collection.delete(ids=existing_ids)

            batch_size = 100
            total_rows = len(df)
            progress_bar = st.progress(0)
            status_text = st.empty()

            for i in range(0, total_rows, batch_size):
                batch_df = df.iloc[i:min(i + batch_size, total_rows)]
                ids = [str(idx) for idx in batch_df.index]
                texts_to_embed = batch_df["enhanced_text"].fillna("").tolist()
                embeddings = embedding_model.encode(texts_to_embed).tolist()
                metadatas = batch_df[["Link", "TiÃªu Ä‘á»"]].fillna("N/A").to_dict('records')

                if len(ids) == len(embeddings) == len(metadatas):
                    try: collection.add(ids=ids, embeddings=embeddings, metadatas=metadatas)
                    except Exception as add_err: st.error(f"Lá»—i khi thÃªm batch vÃ o ChromaDB: {add_err}"); continue
                else: st.error(f"Lá»—i dá»¯ liá»‡u khÃ´ng khá»›p kÃ­ch thÆ°á»›c á»Ÿ batch {i}"); continue

                percent_complete = min((i + batch_size) / total_rows, 1.0)
                progress_bar.progress(percent_complete)
                status_text.text(f"ÄÃ£ náº¡p {min(i + batch_size, total_rows)} / {total_rows} há»“ sÆ¡.")

            status_text.text(f"Náº¡p dá»¯ liá»‡u cho collection '{collection_name}' hoÃ n táº¥t.")
            st.success(f"ÄÃ£ táº¡o vÃ  náº¡p dá»¯ liá»‡u cho collection '{collection_name}' thÃ nh cÃ´ng!")
        else:
            print(f"Collection '{collection_name}' Ä‘Ã£ cÃ³ Ä‘á»§ dá»¯ liá»‡u ({collection.count()} há»“ sÆ¡).")
        return collection
    except Exception as e:
        st.error(f"Lá»—i khá»Ÿi táº¡o hoáº·c káº¿t ná»‘i ChromaDB: {e}")
        st.stop()

collection = init_chroma_db()

# --- HÃ m Xá»­ lÃ½ Truy váº¥n vÃ  ÄÃ¡nh giÃ¡ báº±ng Gemini ---

# HÃ m tiá»n xá»­ lÃ½ truy váº¥n (cÃ³ thá»ƒ giá»¯ nguyÃªn hoáº·c cáº£i thiá»‡n prompt)
def preprocess_query_with_gemini(query):
    prompt = f"""
    PhÃ¢n tÃ­ch vÃ  tÃ³m táº¯t thÃ´ng tin chÃ­nh tá»« truy váº¥n tÃ¬m ngÆ°á»i thÃ¢n sau Ä‘Ã¢y thÃ nh má»™t Ä‘oáº¡n vÄƒn ngáº¯n gá»n, máº¡ch láº¡c báº±ng tiáº¿ng Viá»‡t. Táº­p trung vÃ o cÃ¡c thá»±c thá»ƒ quan trá»ng: tÃªn (ngÆ°á»i tÃ¬m, ngÆ°á»i Ä‘Æ°á»£c tÃ¬m, cha, máº¹, anh chá»‹ em, ngÆ°á»i nuÃ´i...), nÄƒm (sinh, máº¥t, tháº¥t láº¡c, sá»± kiá»‡n...), Ä‘á»‹a Ä‘iá»ƒm (quÃª quÃ¡n, nÆ¡i á»Ÿ, nÆ¡i tháº¥t láº¡c...), hoÃ n cáº£nh Ä‘áº·c biá»‡t.

    Truy váº¥n gá»‘c:
    "{query}"

    Báº£n tÃ³m táº¯t sÃºc tÃ­ch:
    """
    try:
        llm = genai.GenerativeModel(GEMINI_MODEL_NAME)
        response = llm.generate_content(prompt)
        return response.text if response.parts else query
    except Exception as e:
        st.warning(f"Lá»—i khi xá»­ lÃ½ truy váº¥n báº±ng Gemini: {e}. Sá»­ dá»¥ng truy váº¥n gá»‘c.")
        return query

# *** HÃ€M ÄÃNH GIÃ NGá»® NGHÄ¨A Báº°NG GEMINI ***
def evaluate_match_with_gemini(query, profile_dict):
    """
    Sá»­ dá»¥ng Gemini Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ phÃ¹ há»£p ngá»¯ nghÄ©a giá»¯a truy váº¥n vÃ  há»“ sÆ¡.
    Tráº£ vá» Ä‘iá»ƒm sá»‘ (0-10) vÃ  giáº£i thÃ­ch.
    """
    # Táº¡o prompt chi tiáº¿t
    profile_text_for_prompt = f"""
    TiÃªu Ä‘á»: {profile_dict.get('TiÃªu Ä‘á»', 'N/A')}
    Há» vÃ  tÃªn: {profile_dict.get('Há» vÃ  tÃªn', 'N/A')}
    NÄƒm sinh: {profile_dict.get('NÄƒm sinh', 'N/A')}
    TÃªn cha: {profile_dict.get('TÃªn cha', 'N/A')}
    TÃªn máº¹: {profile_dict.get('TÃªn máº¹', 'N/A')}
    Anh chá»‹ em: {profile_dict.get('TÃªn anh-chá»‹-em', 'N/A')}
    NÄƒm tháº¥t láº¡c: {profile_dict.get('NÄƒm tháº¥t láº¡c', 'N/A')}
    Chi tiáº¿t: {profile_dict.get('Chi tiáº¿t', 'N/A')}
    """

    prompt = f"""
    Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch thÃ´ng tin tÃ¬m kiáº¿m ngÆ°á»i thÃ¢n. HÃ£y Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ phÃ¹ há»£p vá» máº·t NGá»® NGHÄ¨A vÃ  CHI TIáº¾T Cá»T LÃ•I giá»¯a [Truy váº¥n TÃ¬m kiáº¿m] vÃ  [Há»“ sÆ¡ á»¨ng viÃªn] dÆ°á»›i Ä‘Ã¢y cho má»¥c Ä‘Ã­ch tÃ¬m láº¡i ngÆ°á»i thÃ¢n.

    [Truy váº¥n TÃ¬m kiáº¿m]:
    "{query}"

    [Há»“ sÆ¡ á»¨ng viÃªn]:
    {profile_text_for_prompt}

    HÃ£y phÃ¢n tÃ­ch ká»¹ cÃ¡c yáº¿u tá»‘ sau vÃ  cho Ä‘iá»ƒm má»©c Ä‘á»™ quan trá»ng/khá»›p cá»§a tá»«ng yáº¿u tá»‘:
    1.  **TÃªn ngÆ°á»i Ä‘Æ°á»£c tÃ¬m:** So sÃ¡nh tÃªn (tÃªn tháº­t, tÃªn gá»i khÃ¡c) trong truy váº¥n vá»›i tÃªn trong há»“ sÆ¡. Má»©c Ä‘á»™ khá»›p? (Ráº¥t quan trá»ng)
    2.  **TÃªn cha/máº¹:** So sÃ¡nh tÃªn cha/máº¹. Má»©c Ä‘á»™ khá»›p? (Ráº¥t quan trá»ng)
    3.  **NÄƒm tháº¥t láº¡c/NÄƒm sá»± kiá»‡n chÃ­nh:** So sÃ¡nh nÄƒm tháº¥t láº¡c hoáº·c cÃ¡c nÄƒm sá»± kiá»‡n quan trá»ng khÃ¡c. Má»©c Ä‘á»™ khá»›p? (Ráº¥t quan trá»ng)
    4.  **HoÃ n cáº£nh tháº¥t láº¡c:** So sÃ¡nh Ã½ nghÄ©a cá»§a hoÃ n cáº£nh Ä‘Æ°á»£c mÃ´ táº£. CÃ³ tÆ°Æ¡ng Ä‘á»“ng khÃ´ng? (Quan trá»ng)
    5.  **NÄƒm sinh:** So sÃ¡nh nÄƒm sinh (náº¿u cÃ³). Má»©c Ä‘á»™ khá»›p? (Quan trá»ng)
    6.  **Äá»‹a Ä‘iá»ƒm:** So sÃ¡nh Ä‘á»‹a Ä‘iá»ƒm quÃª quÃ¡n, nÆ¡i tháº¥t láº¡c, nÆ¡i á»Ÿ. CÃ³ liÃªn quan khÃ´ng? (KhÃ¡ quan trá»ng)
    7.  **Anh chá»‹ em:** So sÃ¡nh thÃ´ng tin vá» anh chá»‹ em. CÃ³ khá»›p tÃªn nÃ o khÃ´ng? (KhÃ¡ quan trá»ng)
    8.  **MÃ¢u thuáº«n:** CÃ³ thÃ´ng tin nÃ o trong há»“ sÆ¡ mÃ¢u thuáº«n rÃµ rÃ ng vá»›i truy váº¥n khÃ´ng? (Yáº¿u tá»‘ giáº£m Ä‘iá»ƒm)

    Dá»±a trÃªn sá»± cÃ¢n nháº¯c táº§m quan trá»ng vÃ  má»©c Ä‘á»™ khá»›p/mÃ¢u thuáº«n cá»§a cÃ¡c yáº¿u tá»‘ trÃªn, hÃ£y cho **Äiá»ƒm phÃ¹ há»£p tá»•ng thá»ƒ** tá»« 0 Ä‘áº¿n 10 (10 lÃ  khá»›p hoÃ n háº£o vá» ngá»¯ nghÄ©a vÃ  cÃ¡c chi tiáº¿t quan trá»ng nháº¥t) vÃ  má»™t **Giáº£i thÃ­ch ngáº¯n gá»n** lÃ½ do cho Ä‘iá»ƒm sá»‘ Ä‘Ã³.

    Chá»‰ tráº£ lá»i theo Ä‘á»‹nh dáº¡ng sau:
    ÄIá»‚M: [Äiá»ƒm tá»« 0-10]
    GIáº¢I THÃCH: [Giáº£i thÃ­ch ngáº¯n gá»n, táº­p trung vÃ o lÃ½ do chÃ­nh]
    """
    try:
        llm = genai.GenerativeModel(GEMINI_MODEL_NAME)
        # ThÃªm cÃ i Ä‘áº·t an toÃ n náº¿u cáº§n, vÃ­ dá»¥ cháº·n ná»™i dung khÃ´ng phÃ¹ há»£p
        # safety_settings=[...]
        response = llm.generate_content(prompt) #, safety_settings=safety_settings)

        # PhÃ¢n tÃ­ch pháº£n há»“i cá»§a Gemini
        text_response = response.text
        score_match = re.search(r"ÄIá»‚M:\s*(\d+)", text_response)
        explanation_match = re.search(r"GIáº¢I THÃCH:\s*(.+)", text_response, re.DOTALL) # DOTALL Ä‘á»ƒ khá»›p qua nhiá»u dÃ²ng

        score = int(score_match.group(1)) if score_match else 0
        explanation = explanation_match.group(1).strip() if explanation_match else "Lá»—i: KhÃ´ng thá»ƒ trÃ­ch xuáº¥t giáº£i thÃ­ch tá»« Gemini."

        # Giá»›i háº¡n Ä‘iá»ƒm trong khoáº£ng 0-10
        score = max(0, min(10, score))

        return score, explanation

    except Exception as e:
        print(f"Lá»—i khi gá»i Gemini Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ há»“ sÆ¡ {profile_dict.get('TiÃªu Ä‘á»', 'N/A')}: {e}")
        # Tráº£ vá» Ä‘iá»ƒm tháº¥p vÃ  thÃ´ng bÃ¡o lá»—i náº¿u khÃ´ng Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c
        return 0, f"Lá»—i API khi Ä‘Ã¡nh giÃ¡: {e}"

# --- HÃ m TÃ¬m kiáº¿m ChÃ­nh (TÃ­ch há»£p Äa luá»“ng) ---

def search_profiles_multithreaded(query, initial_top_k=50, final_top_k=10, min_score=4):
    """
    TÃ¬m kiáº¿m há»“ sÆ¡:
    1. Tiá»n xá»­ lÃ½ truy váº¥n báº±ng Gemini.
    2. TÃ¬m kiáº¿m vector top `initial_top_k`.
    3. Lá»c sÆ¡ bá»™ cÃ¡c á»©ng viÃªn tiá»m nÄƒng
    4. ÄÃ¡nh giÃ¡ ngá»¯ nghÄ©a tá»«ng á»©ng viÃªn báº±ng Gemini (Ä‘a luá»“ng + hÃ ng loáº¡t).
    5. Sáº¯p xáº¿p theo Ä‘iá»ƒm Gemini vÃ  tráº£ vá» top `final_top_k`.
    """
    start_time = time.time()
    st.info("BÆ°á»›c 1: PhÃ¢n tÃ­ch vÃ  chuáº©n hÃ³a truy váº¥n...")
    processed_query = preprocess_query_with_gemini(query)
    st.write("**ThÃ´ng tin trÃ­ch xuáº¥t (dÃ¹ng Ä‘á»ƒ tÃ¬m kiáº¿m vector):**", processed_query if processed_query != query else "(KhÃ´ng trÃ­ch xuáº¥t Ä‘Æ°á»£c thÃªm, dÃ¹ng truy váº¥n gá»‘c)")
    query_for_embedding = processed_query # Sá»­ dá»¥ng truy váº¥n Ä‘Ã£ xá»­ lÃ½ cho vector search

    st.info(f"BÆ°á»›c 2: TÃ¬m kiáº¿m {initial_top_k} há»“ sÆ¡ tiá»m nÄƒng báº±ng Vector Search...")
    try:
        query_vector = embedding_model.encode(query_for_embedding).tolist()
        results = collection.query(
            query_embeddings=[query_vector],
            n_results=initial_top_k,
            include=["metadatas"] # Chá»‰ cáº§n metadata Ä‘á»ƒ láº¥y link/tiÃªu Ä‘á»
        )
    except Exception as e:
        st.error(f"Lá»—i khi truy váº¥n ChromaDB: {e}")
        return [], None

    retrieved_ids = results.get("ids", [[]])[0]
    if not retrieved_ids:
        st.warning("Vector Search khÃ´ng tráº£ vá» káº¿t quáº£ nÃ o.")
        return [], None

    # Láº¥y dá»¯ liá»‡u Ä‘áº§y Ä‘á»§ cá»§a cÃ¡c á»©ng viÃªn tá»« DataFrame gá»‘c
    retrieved_indices = [int(id_str) for id_str in retrieved_ids if id_str.isdigit()]
    candidate_profiles_df = df.iloc[retrieved_indices].copy()

    # Gáº¯n link/tiÃªu Ä‘á» tá»« metadata
    metadata_map = {id_str: meta for id_str, meta in zip(results["ids"][0], results["metadatas"][0])}
    candidate_profiles_df['Link'] = candidate_profiles_df.index.map(lambda idx: metadata_map.get(str(idx), {}).get('Link', ''))
    candidate_profiles_df['TiÃªu Ä‘á»'] = candidate_profiles_df.index.map(lambda idx: metadata_map.get(str(idx), {}).get('TiÃªu Ä‘á»', candidate_profiles_df.loc[idx, 'TiÃªu Ä‘á»']))

    # ------- PHáº¦N Má»šI: Lá»ŒC SÆ  Bá»˜ á»¨NG VIÃŠN -------
    total_candidates = len(retrieved_indices)
    st.info(f"BÆ°á»›c 3: SÃ ng lá»c sÆ¡ bá»™ {total_candidates} há»“ sÆ¡ trÆ°á»›c khi phÃ¢n tÃ­ch chi tiáº¿t...")

    # TrÃ­ch xuáº¥t tá»« khÃ³a quan trá»ng nháº¥t tá»« truy váº¥n
    key_names = re.findall(r'tÃªn\s+(?:lÃ )?\s+([A-ZÃ€-á»¸a-zÃ -á»¹]+(?:\s+[A-ZÃ€-á»¸a-zÃ -á»¹]+){0,2})', query, re.IGNORECASE)
    key_years = extract_years(query)
    parent_names = (
        re.findall(r'(?:cha|ba|bá»‘)\s+(?:tÃªn|lÃ )\s+([A-ZÃ€-á»¸a-zÃ -á»¹]+(?:\s+[A-ZÃ€-á»¸a-zÃ -á»¹]+){0,2})', query, re.IGNORECASE) + 
        re.findall(r'(?:máº¹|mÃ¡)\s+(?:tÃªn|lÃ )\s+([A-ZÃ€-á»¸a-zÃ -á»¹]+(?:\s+[A-ZÃ€-á»¸a-zÃ -á»¹]+){0,2})', query, re.IGNORECASE)
    )
    
    # Lá»c sÆ¡ bá»™ cÃ¡c á»©ng viÃªn cÃ³ kháº£ nÄƒng cao
    filtered_candidates = []
    
    for index, profile_row in candidate_profiles_df.iterrows():
        profile_dict = profile_row.to_dict()
        prefilter_score = 0
        
        # Kiá»ƒm tra tá»«ng tá»« khÃ³a trong profile
        profile_text = (str(profile_dict.get("Há» vÃ  tÃªn", "")) + " " + 
                        str(profile_dict.get("Chi tiáº¿t", "")) + " " + 
                        str(profile_dict.get("TÃªn cha", "")) + " " + 
                        str(profile_dict.get("TÃªn máº¹", ""))).lower()
        
        # Cho Ä‘iá»ƒm sÆ¡ bá»™ dá»±a trÃªn tÃªn
        for name in key_names:
            if normalize_name(name) in profile_text:
                prefilter_score += 3
        
        # Cho Ä‘iá»ƒm sÆ¡ bá»™ dá»±a trÃªn nÄƒm
        for year in key_years:
            if year in profile_text:
                prefilter_score += 2
        
        # Cho Ä‘iá»ƒm sÆ¡ bá»™ dá»±a trÃªn tÃªn cha máº¹
        for parent in parent_names:
            if normalize_name(parent) in profile_text:
                prefilter_score += 3
        
        # Chá»‰ giá»¯ láº¡i cÃ¡c profile cÃ³ Ä‘iá»ƒm sÆ¡ bá»™ >= 2
        if prefilter_score >= 2:
            filtered_candidates.append((query, profile_dict))
    
    # Thá»‘ng kÃª lá»c sÆ¡ bá»™
    filtered_count = len(filtered_candidates)
    if filtered_count == 0:
        # Náº¿u khÃ´ng cÃ³ á»©ng viÃªn nÃ o qua lá»c sÆ¡ bá»™, láº¥y 10 á»©ng viÃªn tá»‘t nháº¥t theo vector
        filtered_candidates = [(query, candidate_profiles_df.iloc[i].to_dict()) for i in range(min(10, len(candidate_profiles_df)))]
        filtered_count = len(filtered_candidates)
        st.warning(f"KhÃ´ng cÃ³ á»©ng viÃªn nÃ o qua Ä‘Æ°á»£c bá»™ lá»c sÆ¡ bá»™. Chá»n {filtered_count} há»“ sÆ¡ tá»‘t nháº¥t theo vector.")
    else:
        st.info(f"Sau khi lá»c sÆ¡ bá»™: {filtered_count}/{total_candidates} há»“ sÆ¡ Ä‘Æ°á»£c Ä‘Æ°a tá»›i Gemini API")
    
    # ------- PHáº¦N Má»šI: ÄÃNH GIÃ HÃ€NG LOáº T -------
    st.info(f"BÆ°á»›c 4: ÄÃ¡nh giÃ¡ chi tiáº¿t {filtered_count} há»“ sÆ¡ báº±ng AI (Gemini) - Sá»­ dá»¥ng Ä‘Ã¡nh giÃ¡ hÃ ng loáº¡t...")
    
    BATCH_SIZE = 3  # ÄÃ¡nh giÃ¡ 3 há»“ sÆ¡ má»—i láº§n gá»i API
    batched_tasks = []
    for i in range(0, len(filtered_candidates), BATCH_SIZE):
        batch = filtered_candidates[i:i+BATCH_SIZE]
        batched_tasks.append(batch)
    
    # Chuyá»ƒn Ä‘á»•i batch profile thÃ nh text Ä‘á»ƒ gá»i Gemini API
    def evaluate_batch_with_gemini(batch):
        """ÄÃ¡nh giÃ¡ má»™t nhÃ³m profile cÃ¹ng lÃºc"""
        query_data, profile_dicts = batch[0][0], [item[1] for item in batch]  # Láº¥y query tá»« batch Ä‘áº§u tiÃªn
        
        # Táº¡o dá»¯ liá»‡u batch Ä‘á»ƒ gá»­i Ä‘i
        profiles_text = ""
        for i, profile in enumerate(profile_dicts):
            profiles_text += f"""
            === Há»’ SÆ  {i+1} ===
            TiÃªu Ä‘á»: {profile.get('TiÃªu Ä‘á»', 'N/A')}
            Há» vÃ  tÃªn: {profile.get('Há» vÃ  tÃªn', 'N/A')}
            NÄƒm sinh: {profile.get('NÄƒm sinh', 'N/A')}
            TÃªn cha: {profile.get('TÃªn cha', 'N/A')}
            TÃªn máº¹: {profile.get('TÃªn máº¹', 'N/A')}
            Chi tiáº¿t: {profile.get('Chi tiáº¿t', 'N/A')}
            NÄƒm tháº¥t láº¡c: {profile.get('NÄƒm tháº¥t láº¡c', 'N/A')}
            """
        
        # Prompt Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ nhiá»u profile cÃ¹ng lÃºc
        prompt = f"""
        Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch thÃ´ng tin tÃ¬m kiáº¿m ngÆ°á»i thÃ¢n. HÃ£y Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ phÃ¹ há»£p vá» máº·t NGá»® NGHÄ¨A vÃ  CHI TIáº¾T Cá»T LÃ•I giá»¯a [Truy váº¥n TÃ¬m kiáº¿m] vÃ  cÃ¡c [Há»“ sÆ¡ á»¨ng viÃªn] dÆ°á»›i Ä‘Ã¢y:

        [Truy váº¥n TÃ¬m kiáº¿m]:
        "{query_data}"

        [CÃ¡c Há»“ sÆ¡ á»¨ng viÃªn]:
        {profiles_text}

        Cho má»—i há»“ sÆ¡, hÃ£y phÃ¢n tÃ­ch vÃ  Ä‘Ã¡nh giÃ¡:
        1. TÃªn ngÆ°á»i Ä‘Æ°á»£c tÃ¬m
        2. TÃªn cha/máº¹
        3. NÄƒm tháº¥t láº¡c/sá»± kiá»‡n
        4. HoÃ n cáº£nh tháº¥t láº¡c
        5. NÄƒm sinh
        6. CÃ¡c yáº¿u tá»‘ khÃ¡c cÃ³ liÃªn quan

        Tráº£ vá» káº¿t quáº£ theo Ä‘á»‹nh dáº¡ng chÃ­nh xÃ¡c sau Ä‘Ã¢y (cho tá»«ng há»“ sÆ¡):
        
        Há»’ SÆ  1:
        ÄIá»‚M: [0-10]
        GIáº¢I THÃCH: [Giáº£i thÃ­ch ngáº¯n gá»n]
        
        Há»’ SÆ  2:
        ÄIá»‚M: [0-10]
        GIáº¢I THÃCH: [Giáº£i thÃ­ch ngáº¯n gá»n]
        
        [vv...]
        """
        
        try:
            llm = genai.GenerativeModel(GEMINI_MODEL_NAME)
            response = llm.generate_content(prompt)
            text_response = response.text
            
            # Parse káº¿t quáº£
            results = []
            pattern = r"Há»’ SÆ  (\d+):\s*ÄIá»‚M:\s*(\d+)\s*GIáº¢I THÃCH:\s*(.+?)(?=Há»’ SÆ  \d+:|$)"
            matches = re.finditer(pattern, text_response, re.DOTALL)
            
            for match in matches:
                profile_num = int(match.group(1))
                if profile_num <= len(profile_dicts):  # Äáº£m báº£o index há»£p lá»‡
                    score = int(match.group(2))
                    explanation = match.group(3).strip()
                    results.append((score, explanation))
            
            # Äáº£m báº£o Ä‘á»§ káº¿t quáº£ cho táº¥t cáº£ profile trong batch
            while len(results) < len(profile_dicts):
                results.append((0, "Lá»—i: KhÃ´ng phÃ¢n tÃ­ch Ä‘Æ°á»£c"))
                
            return list(zip(profile_dicts, [r[0] for r in results], [r[1] for r in results]))
        
        except Exception as e:
            print(f"Lá»—i khi Ä‘Ã¡nh giÃ¡ batch: {e}")
            # Tráº£ vá» Ä‘iá»ƒm 0 cho táº¥t cáº£ profile trong batch náº¿u lá»—i
            return [(p, 0, f"Lá»—i API: {str(e)}") for p in profile_dicts]
    
    # Thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ theo batch Ä‘a luá»“ng
    evaluated_results = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    evaluated_count = 0
    lock = Lock()
    
    def process_batch(batch):
        nonlocal evaluated_count
        batch_results = evaluate_batch_with_gemini(batch)
        with lock:
            evaluated_count += len(batch)
            progress = min(evaluated_count / filtered_count, 1.0)
            progress_bar.progress(progress)
            status_text.text(f"Äang Ä‘Ã¡nh giÃ¡: {evaluated_count}/{filtered_count} há»“ sÆ¡...")
        return batch_results
    
    start_eval_time = time.time()
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS_GEMINI) as executor:
        future_to_batch = {executor.submit(process_batch, batch): batch for batch in batched_tasks}
        
        for future in concurrent.futures.as_completed(future_to_batch):
            try:
                batch_results = future.result()
                evaluated_results.extend(batch_results)
            except Exception as exc:
                original_batch = future_to_batch[future]
                print(f"Batch cÃ³ {len(original_batch)} há»“ sÆ¡ táº¡o ra lá»—i: {exc}")
                # ThÃªm lá»—i vÃ o káº¿t quáº£
                for _, profile_dict in original_batch:
                    evaluated_results.append((profile_dict, 0, f"Lá»—i Ä‘Ã¡nh giÃ¡ batch: {exc}"))
                with lock:
                    evaluated_count += len(original_batch)
    
    eval_duration = time.time() - start_eval_time
    status_text.text(f"HoÃ n táº¥t Ä‘Ã¡nh giÃ¡ {filtered_count} há»“ sÆ¡ trong {eval_duration:.2f} giÃ¢y.")

    # Táº­p há»£p káº¿t quáº£ vÃ  táº¡o DataFrame má»›i
    final_profiles_data = []
    for profile_dict, score, explanation in evaluated_results:
        profile_dict['gemini_score'] = score
        profile_dict['gemini_explanation'] = explanation
        final_profiles_data.append(profile_dict)

    if not final_profiles_data:
        st.warning("KhÃ´ng cÃ³ há»“ sÆ¡ nÃ o Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ thÃ nh cÃ´ng.")
        return [], None

    final_df = pd.DataFrame(final_profiles_data)

    # Sáº¯p xáº¿p theo Ä‘iá»ƒm Gemini vÃ  lá»c
    final_df.sort_values(by='gemini_score', ascending=False, inplace=True)
    filtered_df = final_df[final_df['gemini_score'] >= min_score]

    # Giá»›i háº¡n sá»‘ lÆ°á»£ng káº¿t quáº£ cuá»‘i cÃ¹ng
    top_profiles = filtered_df.head(final_top_k).to_dict('records')

    total_duration = time.time() - start_time
    st.success(f"BÆ°á»›c 5: HoÃ n táº¥t! TÃ¬m tháº¥y {len(top_profiles)} há»“ sÆ¡ phÃ¹ há»£p nháº¥t (Ä‘iá»ƒm AI >= {min_score}). Tá»•ng thá»i gian: {total_duration:.2f} giÃ¢y.")

    # Tráº£ vá» DataFrame Ä‘Ã£ lá»c vÃ  sáº¯p xáº¿p Ä‘á»ƒ hÃ m check_specific_profile sá»­ dá»¥ng
    return top_profiles, final_df

# --- HÃ m Sinh Pháº£n há»“i Tá»•ng há»£p (Dá»±a trÃªn káº¿t quáº£ Gemini) ---
def generate_final_response_with_gemini(query, profiles_with_scores):
    if not profiles_with_scores:
        return "KhÃ´ng tÃ¬m tháº¥y há»“ sÆ¡ nÃ o cÃ³ Ä‘iá»ƒm phÃ¹ há»£p Ä‘á»§ cao sau khi AI phÃ¢n tÃ­ch."

    # Chá»‰ láº¥y top 5 Ä‘á»ƒ Ä‘Æ°a vÃ o prompt
    top_profiles_for_prompt = profiles_with_scores[:5]

    profiles_text = "\n\n".join([
        f"Há»“ sÆ¡ {i+1} (Äiá»ƒm AI: {p['gemini_score']}/10):\n" +
        f"  TiÃªu Ä‘á»: {p.get('TiÃªu Ä‘á»', 'N/A')}\n" +
        f"  Há» vÃ  tÃªn: {p.get('Há» vÃ  tÃªn', 'N/A')}\n" +
        # f"  NÄƒm sinh: {p.get('NÄƒm sinh', 'N/A')}\n" + # CÃ³ thá»ƒ bá» bá»›t náº¿u quÃ¡ dÃ i
        # f"  TÃªn cha: {p.get('TÃªn cha', 'N/A')}\n" +
        # f"  TÃªn máº¹: {p.get('TÃªn máº¹', 'N/A')}\n" +
        f"  Giáº£i thÃ­ch cá»§a AI: {p.get('gemini_explanation', 'KhÃ´ng cÃ³ giáº£i thÃ­ch.')}"
        for i, p in enumerate(top_profiles_for_prompt)
    ])

    prompt = f"""
    Dá»±a trÃªn truy váº¥n tÃ¬m kiáº¿m ngÆ°á»i thÃ¢n sau:
    "{query}"

    VÃ  Ä‘Ã¢y lÃ  cÃ¡c há»“ sÆ¡ cÃ³ Ä‘iá»ƒm phÃ¹ há»£p cao nháº¥t sau khi Ä‘Æ°á»£c AI (Gemini) phÃ¢n tÃ­ch chi tiáº¿t vá» ngá»¯ nghÄ©a vÃ  cÃ¡c yáº¿u tá»‘ quan trá»ng (tÃªn, nÄƒm, hoÃ n cáº£nh...):
    {profiles_text}

    HÃ£y Ä‘Æ°a ra má»™t phÃ¢n tÃ­ch tá»•ng há»£p cho ngÆ°á»i dÃ¹ng:
    1.  Nháº­n xÃ©t vá» há»“ sÆ¡ tiá»m nÄƒng nháº¥t (cÃ³ Ä‘iá»ƒm AI cao nháº¥t). Táº¡i sao AI láº¡i Ä‘Ã¡nh giÃ¡ cao há»“ sÆ¡ Ä‘Ã³ dá»±a trÃªn giáº£i thÃ­ch Ä‘Ã£ cÃ³?
    2.  Liá»‡t kÃª ngáº¯n gá»n 1-2 há»“ sÆ¡ khÃ¡c cÅ©ng cÃ³ tiá»m nÄƒng (náº¿u cÃ³).
    3.  Náº¿u cÃ³ sá»± khÃ´ng cháº¯c cháº¯n hoáº·c cáº§n thÃªm thÃ´ng tin, hÃ£y Ä‘á» xuáº¥t cho ngÆ°á»i dÃ¹ng.

    Viáº¿t cÃ¢u tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, giá»ng vÄƒn cáº£m thÃ´ng, rÃµ rÃ ng vÃ  táº­p trung vÃ o káº¿t quáº£ phÃ¢n tÃ­ch cá»§a AI.
    """
    try:
        llm = genai.GenerativeModel(GEMINI_MODEL_NAME)
        response = llm.generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"Lá»—i khi táº¡o pháº£n há»“i tá»•ng há»£p báº±ng Gemini: {e}")
        return "ÄÃ£ xáº£y ra lá»—i khi táº¡o phÃ¢n tÃ­ch káº¿t quáº£."

# --- HÃ m kiá»ƒm tra há»“ sÆ¡ cá»¥ thá»ƒ (cáº§n gá»i evaluate_match_with_gemini) ---
def check_specific_profile(query, profile_id_input, all_evaluated_df):
    target_profile_display_info = None
    profile_id_str = profile_id_input.upper()
    if not profile_id_str.startswith("MS"): profile_id_str = "MS" + profile_id_str

    # 1. TÃ¬m trong DataFrame Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ bá»Ÿi Gemini (náº¿u cÃ³)
    if all_evaluated_df is not None and not all_evaluated_df.empty:
        target_in_evaluated = all_evaluated_df[all_evaluated_df['TiÃªu Ä‘á»'].str.contains(profile_id_str, na=False)]
        if not target_in_evaluated.empty:
            target_data = target_in_evaluated.iloc[0].to_dict()
            # TÃ¬m vá»‹ trÃ­ rank trong DataFrame Ä‘Ã£ sort theo gemini_score
            try:
                 # Cáº§n reset index Ä‘á»ƒ .get_loc hoáº¡t Ä‘á»™ng Ä‘Ãºng náº¿u index khÃ´ng liÃªn tá»¥c
                 rank = all_evaluated_df.reset_index(drop=True).index[all_evaluated_df['TiÃªu Ä‘á»'].str.contains(profile_id_str, na=False)][0] + 1
            except IndexError:
                 rank = -1 # KhÃ´ng tÃ¬m tháº¥y (trÆ°á»ng há»£p hiáº¿m)

            target_profile_display_info = {
                "data": target_data, # Chá»©a cáº£ score vÃ  explanation
                "rank": rank,
                "source": "evaluated"
            }
            print(f"TÃ¬m tháº¥y há»“ sÆ¡ má»¥c tiÃªu {profile_id_str} trong danh sÃ¡ch Ä‘Ã£ Ä‘Ã¡nh giÃ¡.")
            return target_profile_display_info

    # 2. Náº¿u khÃ´ng cÃ³ trong danh sÃ¡ch Ä‘Ã£ Ä‘Ã¡nh giÃ¡, tÃ¬m trong DF gá»‘c vÃ  Ä‘Ã¡nh giÃ¡ báº±ng Gemini
    print(f"Há»“ sÆ¡ má»¥c tiÃªu {profile_id_str} khÃ´ng cÃ³ trong top {len(all_evaluated_df) if all_evaluated_df is not None else 0} Ä‘Ã£ Ä‘Ã¡nh giÃ¡. TÃ¬m trong DF gá»‘c...")
    target_df = df[df["TiÃªu Ä‘á»"].str.contains(profile_id_str, na=False)]
    if not target_df.empty:
        target_profile_dict = target_df.iloc[0].to_dict()
        st.info(f"Äang Ä‘Ã¡nh giÃ¡ há»“ sÆ¡ má»¥c tiÃªu '{profile_id_str}' báº±ng AI...")
        # Gá»i hÃ m Ä‘Ã¡nh giÃ¡ (khÃ´ng dÃ¹ng Ä‘a luá»“ng á»Ÿ Ä‘Ã¢y vÃ¬ chá»‰ cÃ³ 1 há»“ sÆ¡)
        gemini_score, gemini_explanation = evaluate_match_with_gemini(query, target_profile_dict)
        st.info(f"ÄÃ¡nh giÃ¡ há»“ sÆ¡ má»¥c tiÃªu '{profile_id_str}' hoÃ n táº¥t.")

        # ThÃªm thÃ´ng tin Ä‘Ã¡nh giÃ¡ vÃ o dict
        target_profile_dict['gemini_score'] = gemini_score
        target_profile_dict['gemini_explanation'] = gemini_explanation

        target_profile_display_info = {
            "data": target_profile_dict,
            "rank": -1, # KhÃ´ng cÃ³ rank vÃ¬ khÃ´ng náº±m trong danh sÃ¡ch sort ban Ä‘áº§u
            "source": "on_demand"
        }
        print(f"ÄÃ£ Ä‘Ã¡nh giÃ¡ há»“ sÆ¡ má»¥c tiÃªu {profile_id_str} (ngoÃ i top): Äiá»ƒm {gemini_score}")
    else:
        print(f"KhÃ´ng tÃ¬m tháº¥y há»“ sÆ¡ má»¥c tiÃªu {profile_id_str} trong toÃ n bá»™ dá»¯ liá»‡u.")

    return target_profile_display_info


# --- Giao diá»‡n Streamlit ---


st.title("ğŸ” Há»‡ thá»‘ng TÃ¬m kiáº¿m NgÆ°á»i thÃ¢n Tháº¥t láº¡c - PhÃ¢n tÃ­ch Ngá»¯ nghÄ©a AI (v3)")
st.markdown("""
Nháº­p thÃ´ng tin báº¡n nhá»› vá» ngÆ°á»i thÃ¢n. AI (Gemini) sáº½ **phÃ¢n tÃ­ch sÃ¢u vá» ngá»¯ nghÄ©a** Ä‘á»ƒ tÃ¬m cÃ¡c há»“ sÆ¡ phÃ¹ há»£p nháº¥t.
*CÃ ng nhiá»u chi tiáº¿t (tÃªn tháº­t, tÃªn cha máº¹, nÄƒm, nÆ¡i á»Ÿ, hoÃ n cáº£nh...) AI cÃ ng dá»… phÃ¢n tÃ­ch chÃ­nh xÃ¡c.*
""")
st.warning("âš ï¸ **LÆ°u Ã½:** Viá»‡c sá»­ dá»¥ng AI Ä‘á»ƒ phÃ¢n tÃ­ch chi tiáº¿t tá»«ng há»“ sÆ¡ cÃ³ thá»ƒ máº¥t thá»i gian vÃ  tá»‘n chi phÃ­ API nhiá»u hÆ¡n.")

col1, col2 = st.columns([2, 1])

with col1:
    query = st.text_area("Nháº­p thÃ´ng tin tÃ¬m kiáº¿m:", height=200, key="query_input", placeholder="VÃ­ dá»¥: TÃ¬m anh trai tÃªn DÅ©ng, cha tÃªn SÃªn, máº¹ tÃªn Váº¡n, quÃª Báº¿n Tre, bá»‹ cho Ä‘i nuÃ´i á»Ÿ VÄ©nh Long khoáº£ng nÄƒm 1981 do cha máº¹ giáº­n nhau...")
    target_profile_id = st.text_input("Kiá»ƒm tra há»“ sÆ¡ cá»¥ thá»ƒ (Nháº­p MSxxxx):", "", key="target_id_input")

with col2:
    st.subheader("TÃ¹y chá»n tÃ¬m kiáº¿m:")
    initial_k = st.slider("Sá»‘ há»“ sÆ¡ quÃ©t ban Ä‘áº§u (Vector Search):", min_value=20, max_value=200, value=50, step=10, key="initial_k", help="Sá»‘ lÆ°á»£ng á»©ng viÃªn tiá»m nÄƒng láº¥y ra tá»« Vector Search Ä‘á»ƒ AI Ä‘Ã¡nh giÃ¡ chi tiáº¿t.")
    final_k = st.slider("Sá»‘ káº¿t quáº£ hiá»ƒn thá»‹ cuá»‘i cÃ¹ng:", min_value=5, max_value=30, value=10, step=5, key="final_k", help="Sá»‘ lÆ°á»£ng há»“ sÆ¡ tá»‘t nháº¥t (theo Ä‘iá»ƒm AI) Ä‘Æ°á»£c hiá»ƒn thá»‹.")
    min_score_threshold = st.slider("NgÆ°á»¡ng Ä‘iá»ƒm AI tá»‘i thiá»ƒu:", min_value=0, max_value=10, value=5, step=1, key="min_score_gemini", help="Chá»‰ hiá»ƒn thá»‹ cÃ¡c há»“ sÆ¡ cÃ³ Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ cá»§a AI lá»›n hÆ¡n hoáº·c báº±ng ngÆ°á»¡ng nÃ y (Thang Ä‘iá»ƒm 0-10).")

if st.button("TÃ¬m kiáº¿m báº±ng AI", key="search_button"):
    if query:
        all_evaluated_profiles_df = None # Khá»Ÿi táº¡o Ä‘á»ƒ kiá»ƒm tra target
        matching_profiles = [] # Khá»Ÿi táº¡o
        with st.spinner(f'ğŸš€ Báº¯t Ä‘áº§u tÃ¬m kiáº¿m... (QuÃ©t {initial_k} há»“ sÆ¡, Ä‘Ã¡nh giÃ¡ báº±ng AI cÃ³ thá»ƒ máº¥t vÃ i phÃºt)'):
            # 1. TÃ¬m kiáº¿m vÃ  Ä‘Ã¡nh giÃ¡ Ä‘a luá»“ng
            matching_profiles, all_evaluated_profiles_df = search_profiles_multithreaded(
                query,
                initial_top_k=initial_k,
                final_top_k=final_k,
                min_score=min_score_threshold
            )

            # 2. Kiá»ƒm tra há»“ sÆ¡ má»¥c tiÃªu (náº¿u cÃ³)
            target_display_info = None
            if target_profile_id:
                with st.spinner(f"Kiá»ƒm tra vÃ  Ä‘Ã¡nh giÃ¡ há»“ sÆ¡ má»¥c tiÃªu '{target_profile_id}'..."):
                     target_display_info = check_specific_profile(query, target_profile_id, all_evaluated_profiles_df)

        # --- Hiá»ƒn thá»‹ káº¿t quáº£ ---
        st.markdown("---")
        st.header("ğŸ“Š Káº¿t quáº£ TÃ¬m kiáº¿m vÃ  PhÃ¢n tÃ­ch AI")

        # Hiá»ƒn thá»‹ thÃ´ng tin há»“ sÆ¡ má»¥c tiÃªu
        if target_display_info:
            st.subheader(f"ThÃ´ng tin Há»“ sÆ¡ Má»¥c tiÃªu ({target_profile_id})")
            target_data = target_display_info['data']
            target_rank = target_display_info['rank']
            target_source = target_display_info['source']

            if target_rank > 0:
                st.success(f"âœ… Há»“ sÆ¡ Ä‘Æ°á»£c tÃ¬m tháº¥y á»Ÿ vá»‹ trÃ­ thá»© **{target_rank}** trong danh sÃ¡ch Ä‘Ã£ Ä‘Ã¡nh giÃ¡.")
            elif target_source == "on_demand":
                 st.warning(f"âš ï¸ Há»“ sÆ¡ Ä‘Æ°á»£c tÃ¬m tháº¥y trong dá»¯ liá»‡u gá»‘c nhÆ°ng khÃ´ng náº±m trong top {initial_k} á»©ng viÃªn ban Ä‘áº§u hoáº·c khÃ´ng Ä‘áº¡t ngÆ°á»¡ng Ä‘iá»ƒm.")
            else: # source == 'evaluated' nhÆ°ng rank = -1 (hiáº¿m)
                 st.warning(f"âš ï¸ Há»“ sÆ¡ cÃ³ trong danh sÃ¡ch Ä‘Ã¡nh giÃ¡ nhÆ°ng khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c vá»‹ trÃ­.")


            st.markdown(f"**TiÃªu Ä‘á»:** {target_data.get('TiÃªu Ä‘á»', 'N/A')}")
            st.markdown(f"**Há» vÃ  tÃªn:** {target_data.get('Há» vÃ  tÃªn', 'N/A')}")
            st.markdown(f"**Äiá»ƒm Ä‘Ã¡nh giÃ¡ AI:** **{target_data.get('gemini_score', 'N/A')} / 10**")
            st.markdown(f"**Giáº£i thÃ­ch cá»§a AI:** {target_data.get('gemini_explanation', 'N/A')}")
            st.markdown(f"**Link gá»‘c:** [{target_data.get('Link', 'N/A')}]({target_data.get('Link', 'N/A')})")
            # st.json(target_data) # Hiá»‡n toÃ n bá»™ data Ä‘á»ƒ debug (náº¿u cáº§n)
            st.markdown("---")
        elif target_profile_id: # Náº¿u nháº­p ID mÃ  khÃ´ng tÃ¬m tháº¥y
             st.warning(f"KhÃ´ng tÃ¬m tháº¥y há»“ sÆ¡ nÃ o cÃ³ mÃ£ sá»‘ '{target_profile_id}' trong toÃ n bá»™ dá»¯ liá»‡u.")
             st.markdown("---")


        # Hiá»ƒn thá»‹ phÃ¢n tÃ­ch tá»•ng há»£p tá»« Gemini
        if matching_profiles:
            st.subheader("ğŸ¤– PhÃ¢n tÃ­ch Tá»•ng há»£p tá»« AI")
            with st.spinner("AI Ä‘ang tÃ³m táº¯t káº¿t quáº£..."):
                 gemini_final_analysis = generate_final_response_with_gemini(query, matching_profiles)
                 st.markdown(gemini_final_analysis)
            st.markdown("---")

            # Hiá»ƒn thá»‹ danh sÃ¡ch cÃ¡c há»“ sÆ¡ phÃ¹ há»£p
            st.subheader(f"Danh sÃ¡ch Top {len(matching_profiles)} há»“ sÆ¡ phÃ¹ há»£p nháº¥t (Äiá»ƒm AI >= {min_score_threshold})")
            for i, profile in enumerate(matching_profiles):
                # Sá»­ dá»¥ng st.container Ä‘á»ƒ nhÃ³m thÃ´ng tin cá»§a má»—i há»“ sÆ¡
                with st.container():
                    st.markdown(f"### {i+1}. **{profile.get('TiÃªu Ä‘á»', 'Há»“ sÆ¡ khÃ´ng cÃ³ tiÃªu Ä‘á»')}**")
                    st.markdown(f"**Äiá»ƒm Ä‘Ã¡nh giÃ¡ AI:** <span style='color: red; font-weight: bold;'>{profile.get('gemini_score', 0)} / 10</span>", unsafe_allow_html=True)

                    col_a, col_b = st.columns([1, 2]) # Cá»™t giáº£i thÃ­ch rá»™ng hÆ¡n
                    with col_a:
                         st.markdown(f"**Há» vÃ  tÃªn:** {profile.get('Há» vÃ  tÃªn', 'N/A')}")
                         st.markdown(f"**NÄƒm sinh:** {profile.get('NÄƒm sinh', 'N/A')}")
                         st.markdown(f"**NÄƒm tháº¥t láº¡c:** {profile.get('NÄƒm tháº¥t láº¡c', 'N/A')}")
                         st.markdown(f"**TÃªn cha:** {profile.get('TÃªn cha', 'N/A')}")
                         st.markdown(f"**TÃªn máº¹:** {profile.get('TÃªn máº¹', 'N/A')}")
                         st.markdown(f"**Link gá»‘c:** [{profile.get('Link', 'N/A')}]({profile.get('Link', 'N/A')})")

                    with col_b:
                        st.markdown(f"**Giáº£i thÃ­ch cá»§a AI:**")
                        st.info(f"{profile.get('gemini_explanation', 'KhÃ´ng cÃ³ giáº£i thÃ­ch.')}")

                    with st.expander("Xem chi tiáº¿t gá»‘c cá»§a há»“ sÆ¡"):
                        st.markdown(f"**Anh chá»‹ em:** {profile.get('TÃªn anh-chá»‹-em', 'N/A')}")
                        st.markdown(f"**Chi tiáº¿t:** {profile.get('Chi tiáº¿t', 'KhÃ´ng cÃ³ chi tiáº¿t.')}")
                    st.markdown("---") # ÄÆ°á»ng káº» ngÄƒn cÃ¡ch giá»¯a cÃ¡c há»“ sÆ¡

        elif not target_display_info: # Chá»‰ hiá»ƒn thá»‹ náº¿u khÃ´ng cÃ³ KQ nÃ o vÃ  cÅ©ng ko cÃ³ target phÃ¹ há»£p
            st.error("Ráº¥t tiáº¿c, sau khi AI phÃ¢n tÃ­ch chi tiáº¿t, khÃ´ng tÃ¬m tháº¥y há»“ sÆ¡ nÃ o phÃ¹ há»£p vá»›i thÃ´ng tin báº¡n cung cáº¥p vÃ  Ä‘áº¡t ngÆ°á»¡ng Ä‘iá»ƒm tá»‘i thiá»ƒu.")
            st.info("Máº¹o: HÃ£y thá»­ cung cáº¥p thÃªm chi tiáº¿t, kiá»ƒm tra lá»—i chÃ­nh táº£ trong truy váº¥n, hoáº·c giáº£m nháº¹ ngÆ°á»¡ng Ä‘iá»ƒm AI tá»‘i thiá»ƒu.")

    else:
        st.warning("âš ï¸ Vui lÃ²ng nháº­p thÃ´ng tin vÃ o Ã´ tÃ¬m kiáº¿m.")

# --- ThÃ´ng tin Sidebar ---
st.sidebar.title("Giá»›i thiá»‡u")
st.sidebar.info(
    "Há»‡ thá»‘ng nÃ y sá»­ dá»¥ng Vector Search Ä‘á»ƒ tÃ¬m á»©ng viÃªn tiá»m nÄƒng vÃ  sau Ä‘Ã³ dÃ¹ng AI **Gemini** Ä‘á»ƒ **phÃ¢n tÃ­ch ngá»¯ nghÄ©a sÃ¢u**, so sÃ¡nh chi tiáº¿t truy váº¥n vÃ  há»“ sÆ¡, nháº±m Ä‘Æ°a ra káº¿t quáº£ chÃ­nh xÃ¡c nháº¥t.\n\n"
    "**Äa luá»“ng** Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tÄƒng tá»‘c quÃ¡ trÃ¬nh phÃ¢n tÃ­ch cá»§a AI."
)
st.sidebar.warning("Viá»‡c phÃ¢n tÃ­ch sÃ¢u báº±ng AI cÃ³ thá»ƒ **tá»‘n thá»i gian** vÃ  **chi phÃ­ API** cao hÆ¡n.")
st.sidebar.title("Cáº§n cÃ i Ä‘áº·t")
st.sidebar.markdown("Äá»ƒ cháº¡y á»©ng dá»¥ng nÃ y cá»¥c bá»™:")
st.sidebar.code("""
pip install streamlit pandas chromadb \
sentence-transformers google-generativeai \
thefuzz python-Levenshtein
""")
st.sidebar.markdown(f"VÃ  thay tháº¿ `YOUR_GOOGLE_API_KEY` báº±ng API Key cá»§a báº¡n. Äáº£m báº£o model `{GEMINI_MODEL_NAME}` cÃ³ sáºµn cho key cá»§a báº¡n.")
st.sidebar.markdown(f"Sá»‘ luá»“ng gá»i AI tá»‘i Ä‘a: `{MAX_WORKERS_GEMINI}` (cÃ³ thá»ƒ Ä‘iá»u chá»‰nh trong code).")